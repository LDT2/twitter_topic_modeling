{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import preprocessor as p\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import string\n",
    "import spacy\n",
    "import es_core_news_sm\n",
    "import re\n",
    "\n",
    "from import_data import read_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_text(text, lemmatize = True):\n",
    "    '''\n",
    "    INPUT: string tweet\n",
    "    OUTPUT: str w/ emojis, urls, numbers, and reserved words removed\n",
    "    '''    \n",
    "    def remove_symbols(word, symbol_set):\n",
    "        return ''.join(char for char in word \n",
    "                     if char not in symbol_set)\n",
    "    \n",
    "    def fix_lemmatized_hashtags(tweet):\n",
    "        '''\n",
    "        Lemmatizing function separates # and word.\n",
    "        This function returns string that rejoins hashtags\n",
    "        '''\n",
    "        tokens = []\n",
    "        for i,j in enumerate(tweet.split()):\n",
    "            if j == '#':\n",
    "                j = tweet.split()[i] + tweet.split()[i+1]  \n",
    "                tokens.append(j)\n",
    "                continue\n",
    "            if (tweet.split()[i-1] == '#'):\n",
    "                continue\n",
    "            elif j != '#':\n",
    "                tokens.append(j)\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    # define stopwords\n",
    "    stop_words_sp = stopwords.words('spanish')\n",
    "    stop_words_en = stopwords.words('english')\n",
    "    stop_words = stop_words_sp + stop_words_en + [' ']\n",
    "    \n",
    "    # define punctuation\n",
    "    punct = set('!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~¿… °¡')\n",
    "    \n",
    "    # remove laughter\n",
    "    matcher= re.compile(r'(ja)\\1*')\n",
    "    jaja = [match.group() for match in matcher.finditer(text)]\n",
    "    jaja += ['lol', 'LOL', 'Lol', 'LoL']\n",
    "    \n",
    "    text = ' '.join([ word for word in text.split() if word not in jaja ])\n",
    "    \n",
    "    if lemmatize == True:\n",
    "        # Lemmatize and rejoin\n",
    "        nlp = es_core_news_sm.load()\n",
    "        nlp_text = nlp(text)\n",
    "        text = ' '.join([token.lemma_ for token in nlp_text ])    \n",
    "        text = fix_lemmatized_hashtags(text)\n",
    "        \n",
    "    else:\n",
    "        # Stem and rejoin\n",
    "        stemmer = SnowballStemmer('spanish')\n",
    "        text = ' '.join([stemmer.stem(token) for token in text.split() ])\n",
    "    \n",
    "    # remove emojis, urls, numbers, and reserved words\n",
    "    p.set_options(p.OPT.EMOJI, p.OPT.URL, p.OPT.NUMBER, p.OPT.RESERVED)\n",
    "    clean_text = p.clean(text)\n",
    "    \n",
    "    # split tweet, remove stopwords, and len(words) <= 2\n",
    "    clean_text = [ word for word in clean_text.split() \n",
    "                          if (remove_symbols(word, punct).lower() not in stop_words) \\\n",
    "                              and (word not in punct) \\\n",
    "                              and (len(remove_symbols(word, punct)) > 2) \\\n",
    "                              and (p.clean(remove_symbols(word, punct)) != '')]\n",
    "\n",
    "    clean_text = [ word.lower() if word.startswith('@') else remove_symbols(word, punct).lower()\n",
    "                  for word in clean_text ]\n",
    "    \n",
    "    return clean_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_user_tweets(tweets_vec):\n",
    "    all_tokens = []\n",
    "    for tweet in tweets_vec:\n",
    "        tokens =  preprocessing_text(tweet)\n",
    "        all_tokens += tokens\n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n",
      "/Users/lthomas/Dropbox/galvanize/Capstone/notebooks/import_data.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data1_cleaned[\"tweet_time\"] = pd.to_datetime(data1_cleaned[\"tweet_time\"])\n",
      "/Users/lthomas/Dropbox/galvanize/Capstone/notebooks/import_data.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data1_cleaned['year'] = data1_cleaned.index.year\n",
      "/Users/lthomas/Dropbox/galvanize/Capstone/notebooks/import_data.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data1_cleaned['month'] = data1_cleaned.index.month\n",
      "/Users/lthomas/Dropbox/galvanize/Capstone/notebooks/import_data.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data2_cleaned[\"tweet_time\"] = pd.to_datetime(data2_cleaned[\"tweet_time\"])\n",
      "/Users/lthomas/Dropbox/galvanize/Capstone/notebooks/import_data.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data2_cleaned['year'] = data2_cleaned.index.year\n",
      "/Users/lthomas/Dropbox/galvanize/Capstone/notebooks/import_data.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data2_cleaned['month'] = data2_cleaned.index.month\n"
     ]
    }
   ],
   "source": [
    "data = read_data('../data', 2018, 2018, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df_grp = data.groupby('userid')\n",
    "user_doc = users_df_grp['tweet_text'].apply(grab_user_tweets)\n",
    "user_doc = pd.DataFrame(user_doc).reset_index().rename(index=str, columns={\"tweet_text\": \"tweet_document\"})\n",
    "user_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
